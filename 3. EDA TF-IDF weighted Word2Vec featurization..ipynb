{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c112ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0c3505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_duplicate\n",
       "False    255027\n",
       "True     149263\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "##just checking the dataframe again\n",
    "df.value_counts(df[\"is_duplicate\"]==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a6b7a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encosing questions\n",
    "\n",
    "df[\"question1\"] = df[\"question1\"].apply(lambda x : str(x))\n",
    "df[\"question2\"] = df[\"question2\"].apply(lambda x : str(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfff69ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the step by step guide to invest in share market in india?What is the step by step guide to invest in share market?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merging text\n",
    "questions = list(df[\"question1\"] + df[\"question2\"])\n",
    "questions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1739c8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<404290x110542 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6336617 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(lowercase = False)\n",
    "tfidf.fit_transform(questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccea3f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2tfidf = dict(zip(tfidf.get_feature_names() , tfidf.idf_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ee8f7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.3.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from en_core_web_sm==2.3.1) (2.3.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.25.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.20.3)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.9.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.59.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.12.5)\n",
      "Building wheels for collected packages: en-core-web-sm\n",
      "  Building wheel for en-core-web-sm (setup.py): started\n",
      "  Building wheel for en-core-web-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047106 sha256=78bd3fba2e9000ff26514c8dfbd5a37a45db7ef6d6a59c27b4b4b3d306355ea8\n",
      "  Stored in directory: C:\\Users\\Acer\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-7tr97bk3\\wheels\\ee\\4d\\f7\\563214122be1540b5f9197b52cb3ddb9c4a8070808b22d5a84\n",
      "Successfully built en-core-web-sm\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-2.3.1\n",
      "symbolic link created for C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\spacy\\data\\en <<===>> C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\en_core_web_sm\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "[+] Linking successful\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\en_core_web_sm -->\n",
      "C:\\Users\\Acer\\anaconda3\\lib\\site-packages\\spacy\\data\\en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "# make sure to write this code before importing en_core_web_sm before module\n",
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce883141",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fb3a143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404290/404290 [41:47<00:00, 161.24it/s] \n"
     ]
    }
   ],
   "source": [
    "vecs1 = []\n",
    "for qu1 in tqdm(list(df[\"question1\"])):\n",
    "    doc1 = nlp(qu1)\n",
    "    mean_vec1 = np.zeros([len(doc1) , len(doc1[0].vector)])\n",
    "    \n",
    "    for word1 in doc1:\n",
    "        #word2vec\n",
    "        vec1 = word1.vector\n",
    "        #fetch df scores\n",
    "        \n",
    "        try:\n",
    "            idf = word2tfidf[str(word1)]\n",
    "        except:\n",
    "            idf =0\n",
    "        #compute final vec\n",
    "        mean_vec1 += vec1*idf\n",
    "    mean_vec1 = mean_vec1.mean(axis=0)\n",
    "    vecs1.append(mean_vec1)\n",
    "df[\"q1_feats_m\"] = list(vecs1)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e968eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 404290/404290 [52:42<00:00, 127.83it/s] \n"
     ]
    }
   ],
   "source": [
    "vecs2 = []\n",
    "for qu2 in tqdm(list(df[\"question2\"])):\n",
    "    doc2 = nlp(qu2)\n",
    "    mean_vec2 = np.zeros([len(doc2) , len(doc2[0].vector)])\n",
    "    \n",
    "    for word2 in doc2:\n",
    "        vec2 = word2.vector\n",
    "        \n",
    "        try:\n",
    "            idf = word2tfidf[str(word2)]\n",
    "        except:\n",
    "            idf = 0\n",
    "            \n",
    "            mean_vec2 += vec2*idf\n",
    "    mean_vec2 = mean_vec2.mean(axis = 0)\n",
    "    vecs2.append(mean_vec2)\n",
    "df[\"q2_feats_m\"] = list(vecs2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b7a11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "dfppro = pd.read_csv(\"df_fe_without_preprocessing\",encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90b4c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n",
    "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3 = df.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedb945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_q1 = pd.DataFrame(df3.q1_feats_m.values.tolist(), index= df3.index)\n",
    "df3_q2 = pd.DataFrame(df3.q2_feats_m.values.tolist(), index= df3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dfc9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the final features to csv file\n",
    "if not os.path.isfile('final_features.csv'):\n",
    "    df3_q1['id']=df1['id']\n",
    "    df3_q2['id']=df1['id']\n",
    "    df1  = df1.merge(df2, on='id',how='left')\n",
    "    df2  = df3_q1.merge(df3_q2, on='id',how='left')\n",
    "    result  = df1.merge(df2, on='id',how='left')\n",
    "    result.to_csv('final_features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
